name: CI/CD Pipeline for Staging

permissions:
  security-events: write
  actions: read
  contents: read
  packages: write

on:
  push:
    branches: [staging]
  pull_request:
    branches: [staging]

env:
  REGISTRY: ghcr.io

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'
          cache: 'npm'
          cache-dependency-path: 'frontend/package-lock.json'

      - name: Set up Java
        uses: actions/setup-java@v4
        with:
          java-version: '21'
          distribution: 'temurin'

      - name: Setup Gradle
        uses: gradle/actions/setup-gradle@v3
        with:
          gradle-version: wrapper

      - name: Install frontend dependencies
        working-directory: ./frontend
        run: npm ci

      - name: Run frontend linting
        working-directory: ./frontend
        run: npm run lint

      - name: Run frontend unit tests
        working-directory: ./frontend
        run: npm run test:unit

      - name: Build frontend
        working-directory: ./frontend
        run: npm run build

      - name: Run backend tests
        run: ./gradlew test

      - name: Run backend integration tests
        run: ./gradlew integrationTest || true

      - name: Generate test reports
        if: always()
        run: |
          echo "Frontend tests completed"
          echo "Backend tests completed"

  security-scan:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'

      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        with:
          sarif_file: 'trivy-results.sarif'

  build-and-push:
    needs: [test, security-scan]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/staging'
    outputs:
      image: ${{ steps.image.outputs.image }}
      tailscale_ip: ${{ steps.get-tailscale-ip.outputs.tailscale_ip }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up image name
        run: |
          echo "IMAGE_NAME=$(echo ${{ github.repository }} | tr '[:upper:]' '[:lower:]')" >> $GITHUB_ENV

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push Docker image
        id: build
        uses: docker/build-push-action@v5
        with:
          context: .
          platforms: linux/amd64
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Output image
        id: image
        run: |
          IMAGE_NAME_LOWER=$(echo ${{ github.repository }} | tr '[:upper:]' '[:lower:]')
          echo "image=${{ env.REGISTRY }}/${IMAGE_NAME_LOWER}:${{ github.ref_name }}" >> $GITHUB_OUTPUT

  deploy-staging:
    needs: build-and-push
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/staging'
    environment: staging
    outputs:
      tailscale_ip: ${{ steps.set-tailscale-ip.outputs.tailscale_ip }}
    steps:
      - name: Deploy to staging via SSH
        uses: appleboy/ssh-action@v1.0.3
        with:
          host: ${{ secrets.DROPLET_IP }}
          username: ${{ secrets.DROPLET_USER }}
          key: ${{ secrets.DROPLET_SSH_KEY }}
          passphrase: ${{ secrets.DROPLET_SSH_PASSPHRASE }}
          port: ${{ secrets.DROPLET_SSH_PORT || 22 }}
          script: |
            set -e
            cd /opt/app
            
            echo "Starting staging deployment via SSH..."
            
            # Get Tailscale IP for binding
            TAILSCALE_IP=$(tailscale ip -4)
            echo "Tailscale IP: $TAILSCALE_IP"
            
            # Verify Tailscale is running
            if ! systemctl is-active --quiet tailscaled; then
                echo "ERROR: Tailscale is not running"
                exit 1
            fi
            
            # Create docker-compose override for staging (bind to Tailscale IP only)
            cat > docker-compose.staging.yml << EOF
            services:
              app:
                image: ${{ needs.build-and-push.outputs.image }}
                environment:
                  SPRING_PROFILES_ACTIVE: staging
                ports:
                  - "${TAILSCALE_IP}:8081:8080"  # Bind only to Tailscale IP
                restart: unless-stopped
                networks:
                  - app-network
                logging:
                  driver: "json-file"
                  options:
                    max-size: "10m"
                    max-file: "3"
            
            networks:
              app-network:
                driver: bridge
            EOF
            
            # Pull latest image
            echo "Pulling image: ${{ needs.build-and-push.outputs.image }}"
            docker pull ${{ needs.build-and-push.outputs.image }}
            
            # Stop existing staging container
            echo "Stopping existing staging container..."
            docker-compose -f docker-compose.staging.yml down || true
            
            # Start new container
            echo "Starting new staging container..."
            docker-compose -f docker-compose.staging.yml up -d
            
            # Wait for application to start
            echo "Waiting for application to start..."
            sleep 30
            
            # Health check via Tailscale IP (local to the server)
            echo "Running health check..."
            for i in {1..10}; do
              if curl -f --max-time 10 http://${TAILSCALE_IP}:8081/actuator/health; then
                echo "Staging health check passed"
                break
              else
                echo "Health check attempt $i failed, retrying..."
                sleep 10
                if [ $i -eq 10 ]; then
                  echo "Staging health check failed after 10 attempts"
                  docker logs $(docker-compose -f docker-compose.staging.yml ps -q app) --tail 50
                  exit 1
                fi
              fi
            done
            
            # Security verification - ensure NOT accessible from public IP
            PUBLIC_IP=$(curl -s ifconfig.me)
            echo "Verifying staging is not accessible from public IP: $PUBLIC_IP"
            if timeout 5 bash -c "</dev/tcp/$PUBLIC_IP/8081" 2>/dev/null; then
                echo "CRITICAL SECURITY ISSUE: Staging accessible from public IP!"
                exit 1
            else
                echo "Security check passed - staging not accessible from public IP"
            fi
            
            # Clean up old images
            docker image prune -af --filter "until=24h"
            
            echo "Staging deployment completed successfully!"
            echo "Access URL (Tailscale only): http://${TAILSCALE_IP}:8081"

      - name: Get Tailscale IP for output
        id: get-tailscale-ip
        uses: appleboy/ssh-action@v1.0.3
        with:
          host: ${{ secrets.DROPLET_IP }}
          username: ${{ secrets.DROPLET_USER }}
          key: ${{ secrets.DROPLET_SSH_KEY }}
          passphrase: ${{ secrets.DROPLET_SSH_PASSPHRASE }}
          port: '22'
          script: |
            tailscale ip -4

      - name: Set Tailscale IP output
        id: set-tailscale-ip
        run: |
          echo "tailscale_ip=${{ steps.get-tailscale-ip.outputs.stdout }}" >> $GITHUB_OUTPUT

  notify-staging-ready:
    needs: deploy-staging
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/staging'
    steps:
      - name: Notify staging deployment
        run: |
          echo "Staging deployment completed!"
          echo "Access URL: http://${{ needs.deploy-staging.outputs.tailscale_ip }}:8081"
          echo "Only accessible via Tailscale network"
          echo "Manual testing required"
  # TODO: Set up Ubuntu server on school computer for self hosted runner.

  deploy-production:
    needs: [deploy-staging]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    environment: production
    steps:
      - name: Deploy to production via SSH
        uses: appleboy/ssh-action@v1.0.3
        with:
          host: ${{ secrets.PRODUCTION_HOST }}
          username: ${{ secrets.PRODUCTION_USER }}
          key: ${{ secrets.PRODUCTION_SSH_KEY }}
          port: ${{ secrets.PRODUCTION_SSH_PORT || 22 }}
          script: |
            set -e
            cd /opt/app
            
            echo "Starting production deployment..."
            
            # Create docker-compose override for production (public access)
            cat > docker-compose.production.yml << EOF
            services:
              app:
                image: ${{ needs.build-and-push.outputs.image }}
                environment:
                  SPRING_PROFILES_ACTIVE: production
                ports:
                  - "80:8080"  # Public access
                restart: unless-stopped
                networks:
                  - app-network
                logging:
                  driver: "json-file"
                  options:
                    max-size: "10m"
                    max-file: "3"
            
            networks:
              app-network:
                driver: bridge
            EOF
            
            # Pull latest image
            echo "Pulling image: ${{ needs.build-and-push.outputs.image }}"
            docker pull ${{ needs.build-and-push.outputs.image }}
            
            # Blue-green deployment
            echo "Starting new production container..."
            docker-compose -f docker-compose.production.yml up -d --force-recreate
            
            # Health check
            echo "Running production health check..."
            for i in {1..15}; do
              if curl -f --max-time 10 http://localhost:80/actuator/health; then
                echo "Production health check passed"
                break
              else
                echo "Health check attempt $i failed, retrying..."
                sleep 10
                if [ $i -eq 15 ]; then
                  echo "Production deployment failed - rolling back"
                  docker-compose -f docker-compose.production.yml down
                  exit 1
                fi
              fi
            done
            
            # Clean up old images
            docker image prune -af --filter "until=72h"
            
            echo "Production deployment completed successfully!"
            echo "Public access: http://${{ secrets.DROPLET_IP }}"